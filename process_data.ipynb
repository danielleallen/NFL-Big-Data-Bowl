{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_track_2020 = pd.read_csv(\"data_sets/tracking2020.csv\")\n",
    "df_track_2019 = pd.read_csv(\"data_sets/tracking2019.csv\")\n",
    "df_track_2018 = pd.read_csv(\"data_sets/tracking2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = pd.read_csv(\"data_sets/games.csv\")\n",
    "df_plays = pd.read_csv(\"data_sets/plays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_play_data(df_plays, kickoff):\n",
    "    '''\n",
    "    Get the necessary columns from the plays dataframe and select only the rows that are for kickoffs where there\n",
    "    was actually a return on the play\n",
    "    '''\n",
    "    if kickoff:       \n",
    "        kick_plays_df = df_plays[(df_plays[\"specialTeamsPlayType\"] == \"Kickoff\") & (df_plays[\"specialTeamsResult\"] == \"Return\")]\n",
    "    else:\n",
    "        kick_plays_df = df_plays[(df_plays[\"specialTeamsPlayType\"] == \"Punt\") & (df_plays[\"specialTeamsResult\"] == \"Return\")]\n",
    "    kick_plays_df = kick_plays_df[[\"gameId\", \"playId\", \"possessionTeam\", \"returnerId\", \"kickReturnYardage\"]]  \n",
    "    # Get rid of onside kicks\n",
    "    kick_plays_df.dropna(axis=0, how='any', subset=['returnerId'], inplace=True)  \n",
    "    # Get rid of kicks with multiple returners\n",
    "    kick_plays_df.drop(kick_plays_df[kick_plays_df['returnerId'].str.contains(';')].index, inplace = True)  \n",
    "    kick_plays_df[\"returnerId\"] = kick_plays_df[\"returnerId\"].astype('int')\n",
    "    # Get rid of kicks with no return yards listed (likely because of fumble)\n",
    "    kick_plays_df.dropna(axis=0, how='any', subset=['kickReturnYardage'], inplace=True) \n",
    "    \n",
    "    return kick_plays_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tracking_data(df_track_2018, df_track_2019, df_track_2020, kickoff):\n",
    "    '''\n",
    "    Get the necessary data from the player tracking dataframes, standardize directions,\n",
    "    and add additional features (velocity)\n",
    "    '''\n",
    "    tracking_df = pd.concat([df_track_2018, df_track_2019, df_track_2020])\n",
    "    if kickoff:\n",
    "        tracking_df = tracking_df[tracking_df[\"event\"] == \"kick_received\"]\n",
    "    else:\n",
    "        tracking_df = tracking_df[tracking_df[\"event\"] == \"punt_received\"]\n",
    "    # Get rid of tracking data on football\n",
    "    tracking_df.drop(tracking_df[tracking_df['team'] == \"football\"].index, inplace = True) \n",
    "    \n",
    "    tracking_df['dir'] = np.mod(90 - tracking_df['dir'], 360)  # Change 0 degrees to be pointing downfield\n",
    "    standardize_tracking_data(tracking_df)\n",
    "    add_velocity_vectors_tracking_data(tracking_df)\n",
    "    \n",
    "    tracking_df[\"nflId\"] = tracking_df[\"nflId\"].astype('int')\n",
    "    tracking_df = tracking_df[['gameId','playId','nflId','team', 'x', 'y', 'v_x', 'v_y']]\n",
    "        \n",
    "    return tracking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_tracking_data(df_tracking):\n",
    "    '''\n",
    "    Standardize the positions and directions of the play so that the returning team is always\n",
    "    going from left to right\n",
    "    '''\n",
    "    df_tracking.loc[df_tracking['playDirection'] == \"right\", 'x'] = 120-df_tracking.loc[df_tracking['playDirection'] == \"right\", 'x']\n",
    "    df_tracking.loc[df_tracking['playDirection'] == \"right\", 'y'] = 160/3-df_tracking.loc[df_tracking['playDirection'] == \"right\", 'y']\n",
    "    df_tracking.loc[df_tracking['playDirection'] == \"right\", 'dir'] = np.mod(180 + df_tracking.loc[df_tracking['playDirection'] == \"right\", 'dir'], 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_velocity_vectors_tracking_data(df_tracking):\n",
    "    '''\n",
    "    Use speed and direction to get the player's velocity in the x, y direction and add these as columns to df\n",
    "    '''\n",
    "    df_tracking[\"v_x\"] = df_tracking[\"s\"] * df_tracking[\"dir\"].apply(math.radians).apply(math.cos)\n",
    "    df_tracking[\"v_y\"] = df_tracking[\"s\"] * df_tracking[\"dir\"].apply(math.radians).apply(math.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_game_data(df_games):\n",
    "    '''\n",
    "    Select the necessary columns from the games df\n",
    "    '''\n",
    "    df_games_slim = df_games[['gameId', 'homeTeamAbbr', 'visitorTeamAbbr']]\n",
    "    return df_games_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tables(df_games, df_kick_plays, df_tracking):\n",
    "    '''\n",
    "    Merged the processed games, plays, and tracking data frames together\n",
    "    '''\n",
    "    game_play_merge = pd.merge(df_games, df_kick_plays, how='inner')\n",
    "    all_merge = pd.merge(game_play_merge, df_tracking, how='inner')\n",
    "    return all_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_player_side(play_track_df):\n",
    "    '''\n",
    "    Add column saying whether player is on kicking_team, returning_team, or is the returner\n",
    "    '''\n",
    "    play_track_df[\"team_abbr\"] = np.where(play_track_df[\"team\"] == \"home\", play_track_df[\"homeTeamAbbr\"], play_track_df[\"visitorTeamAbbr\"])\n",
    "    play_track_df[\"player_side\"] = np.where(play_track_df[\"team_abbr\"] == play_track_df[\"possessionTeam\"], \"kicking_team\", \"return_team\")\n",
    "    play_track_df[\"player_side\"] = np.where(play_track_df[\"returnerId\"] == play_track_df[\"nflId\"], \"returner\", play_track_df[\"player_side\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_track_2018, df_track_2019, df_track_2020, df_games, df_plays, kickoff=True):\n",
    "    '''\n",
    "    Process all data to create a single dataframe with all necessary information for the model\n",
    "    '''\n",
    "    kick_plays_df = process_play_data(df_plays, kickoff)\n",
    "    df_games_slim = process_game_data(df_games)\n",
    "    tracking_df = process_tracking_data(df_track_2018, df_track_2019, df_track_2020, kickoff)    \n",
    "    play_track_df = merge_tables(df_games_slim, kick_plays_df, tracking_df)\n",
    "    add_player_side(play_track_df)\n",
    "    \n",
    "    # Get rid of plays where there was not 22 players on field (Sillie billlies)\n",
    "    grouped_df = play_track_df.groupby([\"gameId\", \"playId\"]) \n",
    "    play_track_df = grouped_df.filter(lambda x: x['nflId'].count() == 22)\n",
    "    \n",
    "    return play_track_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_track_df = process_data(df_track_2018, df_track_2019, df_track_2020, df_games, df_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "punt_play_track_df = process_data(df_track_2018, df_track_2019, df_track_2020, df_games, df_plays, kickoff= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_track_df.to_csv(\"play_track_kickoff.csv\", index=False)\n",
    "punt_play_track_df.to_csv(\"play_track_punt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Frames to Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_tensor(play_track_df):\n",
    "    '''\n",
    "    Creates X input tensor for model. \n",
    "    Returns numpy array of shape (num_plays, 11, 10, 10)\n",
    "    '''\n",
    "    grouped_df = play_track_df.groupby([\"gameId\", \"playId\"])\n",
    "    print(len(grouped_df))\n",
    "    train_x = np.zeros([len(grouped_df),11,10,10])\n",
    "    \n",
    "    i = 0\n",
    "    for name, group in grouped_df:\n",
    "        [[returner_x, returner_y, returner_Vx, returner_Vy]] = group.loc[group.player_side==\"returner\",['x', 'y','v_x','v_y']].values\n",
    "\n",
    "        kick_team_ids = group[group.player_side == \"kicking_team\"].index\n",
    "        return_team_ids = group[group.player_side == \"return_team\"].index\n",
    "\n",
    "        for j, kick_team_id in enumerate(kick_team_ids):\n",
    "            [kick_team_x, kick_team_y, kick_team_Vx, kick_team_Vy] = group.loc[kick_team_id,['x', 'y','v_x','v_y']].values\n",
    "\n",
    "            [kick_team_returner_x, kick_team_returner_y] = group.loc[kick_team_id,['x', 'y']].values - np.array([returner_x, returner_y])\n",
    "            [kick_team_returner_Vx, kick_team_returner_Vy] = group.loc[kick_team_id,['v_x', 'v_y']].values - np.array([returner_Vx, returner_Vy])\n",
    "\n",
    "            train_x[i,j,:,:4] = group.loc[return_team_ids,['v_x','v_y','x', 'y']].values - np.array([kick_team_x, kick_team_y, kick_team_Vx, kick_team_Vy])\n",
    "            train_x[i,j,:,-6:] = [kick_team_returner_Vx, kick_team_returner_Vy, kick_team_returner_x, kick_team_returner_y, kick_team_Vx, kick_team_Vy]\n",
    "        i += 1\n",
    "    \n",
    "    return train_x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_train(play_track_df):\n",
    "    '''\n",
    "    Create dataframe of y data for the model. \n",
    "    Adds 99 yards so that we can never have negative yards on play and also \n",
    "    \"clips\" yard gained so it can never be above or below certain values\n",
    "    '''\n",
    "    # These were set by original model, maybe I want to change these\n",
    "    min_idx_y = 71    # Min yards gained = 28\n",
    "    max_idx_y = 150   # Max yards gained = 51\n",
    "    \n",
    "    train_y = play_track_df.groupby([\"gameId\", \"playId\"])[\"kickReturnYardage\"].mean()\n",
    "    train_y = train_y.to_frame()\n",
    "    train_y.reset_index(level=[\"gameId\", \"playId\"], inplace=True)\n",
    "    \n",
    "    train_y['YardIndex'] = train_y[\"kickReturnYardage\"].apply(lambda val: val + 99)\n",
    "    train_y['YardIndexClipped'] = train_y['YardIndex'].apply(\n",
    "        lambda val: min_idx_y if val < min_idx_y else max_idx_y if val > max_idx_y else val)\n",
    "    \n",
    "    print('max yardIndex: ', train_y.YardIndex.max())\n",
    "    print('max yardIndexClipped: ', train_y.YardIndexClipped.max())\n",
    "    print('min yardIndex: ', train_y.YardIndex.min())\n",
    "    print('min yardIndexClipped: ', train_y.YardIndexClipped.min())\n",
    "    \n",
    "    return train_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_tensor(train_y, min_idx_y, max_idx_y):\n",
    "    '''\n",
    "    For each play, create a one-hot encoded vector for yards gained\n",
    "    Returns numpy array of shape (num_plays, num_y_classes) where num_y_classes\n",
    "    is the number of different yards that can be predicted\n",
    "    '''\n",
    "    num_classes_y = max_idx_y - min_idx_y + 1\n",
    "    y_vals = train_y[\"YardIndexClipped\"].values\n",
    "    y_tensor = np.zeros((len(y_vals), num_classes_y), np.int32)\n",
    "    for i, yards in enumerate(y_vals):\n",
    "        y_tensor[(i, yards.astype(np.int32) - min_idx_y)] = 1\n",
    "    \n",
    "    return y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(play_track_df, output_tag, test_size=0.1, save_tensors=True):\n",
    "    X_tensor = create_X_tensor(play_track_df)\n",
    "    print(\"X Shape\", X_tensor.shape)\n",
    "    \n",
    "    train_y = create_y_train(play_track_df)\n",
    "    y_tensor = create_y_tensor(train_y, 71, 150)\n",
    "    print(\"y Shape\", y_tensor.shape)\n",
    "    \n",
    "    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=test_size)\n",
    "    \n",
    "    print(\"Train X\", X_train_tensor.shape)\n",
    "    print(\"Test X\", X_test_tensor.shape)\n",
    "    print(\"Train y\", y_train_tensor.shape)\n",
    "    print(\"Test y\", y_test_tensor.shape)\n",
    "    \n",
    "    if save_tensors:\n",
    "        with open(f'input_tensors/X_tensor_{output_tag}_train.data', 'wb') as f:\n",
    "            pickle.dump(X_train_tensor, f)\n",
    "        with open(f'input_tensors/X_tensor_{output_tag}_test.data', 'wb') as f:\n",
    "            pickle.dump(X_test_tensor, f)\n",
    "        with open(f'input_tensors/y_tensor_{output_tag}_train.data', 'wb') as f:\n",
    "            pickle.dump(y_train_tensor, f)\n",
    "        with open(f'input_tensors/y_tensor_{output_tag}_test.data', 'wb') as f:\n",
    "            pickle.dump(y_test_tensor, f)\n",
    "\n",
    "    \n",
    "    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data_combo(kick_play_track_df, punt_play_track_df, output_tag, test_size=0.1):\n",
    "    X_train_kick_tensor, X_test_kick_tensor, y_train_kick_tensor, y_test_kick_tensor = get_input_data(kick_play_track_df, \"kick\", test_size=test_size, save_tensors=False)\n",
    "    X_train_punt_tensor, X_test_punt_tensor, y_train_punt_tensor, y_test_punt_tensor = get_input_data(punt_play_track_df, \"punt\", test_size=test_size, save_tensors=False)\n",
    "    \n",
    "    X_train_comb_tensor = np.concatenate((X_train_kick_tensor, X_train_punt_tensor))\n",
    "    X_test_comb_tensor = np.concatenate((X_test_kick_tensor, X_test_punt_tensor))\n",
    "    y_train_comb_tensor = np.concatenate((y_train_kick_tensor, y_train_punt_tensor))\n",
    "    y_test_comb_tensor = np.concatenate((y_test_kick_tensor, y_test_punt_tensor))\n",
    "    \n",
    "    print(\"X_train_combo\", X_train_comb_tensor.shape)\n",
    "    print(\"X_test_combo\", X_test_comb_tensor.shape)\n",
    "    print(\"y_train_combo\", y_train_comb_tensor.shape)\n",
    "    print(\"y_test_combo\", y_test_comb_tensor.shape)\n",
    "    \n",
    "    shuffle = np.arange(len(X_train_comb_tensor))\n",
    "    np.random.shuffle(shuffle)\n",
    "    X_train_comb_tensor = X_train_comb_tensor[shuffle]\n",
    "    y_train_comb_tensor = y_train_comb_tensor[shuffle]\n",
    "    \n",
    "    print(\"X_train_combo Shuffled\", X_train_comb_tensor.shape)\n",
    "    print(\"y_train_combo Shuffled\", y_train_comb_tensor.shape)\n",
    "    \n",
    "    with open(f'input_tensors/X_tensor_comb_{output_tag}_train.data', 'wb') as f:\n",
    "        pickle.dump(X_train_comb_tensor, f)\n",
    "    with open(f'input_tensors/X_tensor_comb_{output_tag}_test.data', 'wb') as f:\n",
    "        pickle.dump(X_test_comb_tensor, f)\n",
    "    with open(f'input_tensors/y_tensor_comb_{output_tag}_train.data', 'wb') as f:\n",
    "        pickle.dump(y_train_comb_tensor, f)\n",
    "    with open(f'input_tensors/y_tensor_comb_{output_tag}_test.data', 'wb') as f:\n",
    "        pickle.dump(y_test_comb_tensor, f)\n",
    "    \n",
    "    \n",
    "    return X_train_comb_tensor, X_test_comb_tensor, y_train_comb_tensor, y_test_comb_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs For Kickoff Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2764, 11, 10, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = create_X_tensor(play_track_df)\n",
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max yardIndex:  203.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  85.0\n",
      "min yardIndexClipped:  85.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2764, 80)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = create_y_train(play_track_df)\n",
    "y_tensor = create_y_tensor(train_y, 71, 150)\n",
    "y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_tensor.data', 'wb') as f:\n",
    "    pickle.dump(X_tensor, f)\n",
    "with open('y_tensor.data', 'wb') as f:\n",
    "    pickle.dump(y_tensor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2487, 11, 10, 10)\n",
      "(277, 11, 10, 10)\n",
      "(2487, 80)\n",
      "(277, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape)\n",
    "print(X_test_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_tensor_train.data', 'wb') as f:\n",
    "    pickle.dump(X_train_tensor, f)\n",
    "with open('X_tensor_test.data', 'wb') as f:\n",
    "    pickle.dump(X_test_tensor, f)\n",
    "with open('y_tensor_train.data', 'wb') as f:\n",
    "    pickle.dump(y_train_tensor, f)\n",
    "with open('y_tensor_test.data', 'wb') as f:\n",
    "    pickle.dump(y_test_tensor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs for Punts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2259, 11, 10, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_punt_tensor = create_X_tensor(punt_play_track_df)\n",
    "X_punt_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max yardIndex:  198.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  86.0\n",
      "min yardIndexClipped:  86.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2259, 80)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_punt_y = create_y_train(punt_play_track_df)\n",
    "y_punt_tensor = create_y_tensor(train_punt_y, 71, 150)\n",
    "y_punt_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_punt_tensor, X_test_punt_tensor, y_train_punt_tensor, y_test_punt_tensor = train_test_split(X_punt_tensor, y_punt_tensor, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033, 11, 10, 10)\n",
      "(226, 11, 10, 10)\n",
      "(2033, 80)\n",
      "(226, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_punt_tensor.shape)\n",
    "print(X_test_punt_tensor.shape)\n",
    "print(y_train_punt_tensor.shape)\n",
    "print(y_test_punt_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_tensors/X_tensor_punt_train.data', 'wb') as f:\n",
    "    pickle.dump(X_train_punt_tensor, f)\n",
    "with open('input_tensors/X_tensor_punt_test.data', 'wb') as f:\n",
    "    pickle.dump(X_test_punt_tensor, f)\n",
    "with open('input_tensors/y_tensor_punt_train.data', 'wb') as f:\n",
    "    pickle.dump(y_train_punt_tensor, f)\n",
    "with open('input_tensors/y_tensor_punt_test.data', 'wb') as f:\n",
    "    pickle.dump(y_test_punt_tensor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs for Combined Punt Kick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n",
      "(2764, 11, 10, 10)\n",
      "max yardIndex:  203.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  85.0\n",
      "min yardIndexClipped:  85.0\n",
      "(2764, 80)\n"
     ]
    }
   ],
   "source": [
    "X_tensor = create_X_tensor(play_track_df)\n",
    "print(X_tensor.shape)\n",
    "train_y = create_y_train(play_track_df)\n",
    "y_tensor = create_y_tensor(train_y, 71, 150)\n",
    "print(y_tensor.shape)\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(X_tensor, y_tensor, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2487, 11, 10, 10)\n",
      "(277, 11, 10, 10)\n",
      "(2487, 80)\n",
      "(277, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape)\n",
    "print(X_test_tensor.shape)\n",
    "print(y_train_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2259\n",
      "(2259, 11, 10, 10)\n",
      "max yardIndex:  198.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  86.0\n",
      "min yardIndexClipped:  86.0\n",
      "(2259, 80)\n"
     ]
    }
   ],
   "source": [
    "X_punt_tensor = create_X_tensor(punt_play_track_df)\n",
    "print(X_punt_tensor.shape)\n",
    "train_punt_y = create_y_train(punt_play_track_df)\n",
    "y_punt_tensor = create_y_tensor(train_punt_y, 71, 150)\n",
    "print(y_punt_tensor.shape)\n",
    "X_train_punt_tensor, X_test_punt_tensor, y_train_punt_tensor, y_test_punt_tensor = train_test_split(X_punt_tensor, y_punt_tensor, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2033, 11, 10, 10)\n",
      "(226, 11, 10, 10)\n",
      "(2033, 80)\n",
      "(226, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_punt_tensor.shape)\n",
    "print(X_test_punt_tensor.shape)\n",
    "print(y_train_punt_tensor.shape)\n",
    "print(y_test_punt_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_comb_tensor = np.concatenate((X_train_tensor, X_train_punt_tensor))\n",
    "X_test_comb_tensor = np.concatenate((X_test_tensor, X_test_punt_tensor))\n",
    "y_train_comb_tensor = np.concatenate((y_train_tensor, y_train_punt_tensor))\n",
    "y_test_comb_tensor = np.concatenate((y_test_tensor, y_test_punt_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4520, 11, 10, 10)\n",
      "(503, 11, 10, 10)\n",
      "(4520, 80)\n",
      "(503, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_comb_tensor.shape)\n",
    "print(X_test_comb_tensor.shape)\n",
    "print(y_train_comb_tensor.shape)\n",
    "print(y_test_comb_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_tensors/X_tensor_comb_train.data', 'wb') as f:\n",
    "    pickle.dump(X_train_comb_tensor, f)\n",
    "with open('input_tensors/X_tensor_comb_test.data', 'wb') as f:\n",
    "    pickle.dump(X_test_comb_tensor, f)\n",
    "with open('input_tensors/y_tensor_comb_train.data', 'wb') as f:\n",
    "    pickle.dump(y_train_comb_tensor, f)\n",
    "with open('input_tensors/y_tensor_comb_test.data', 'wb') as f:\n",
    "    pickle.dump(y_test_comb_tensor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4520"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_comb_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2764\n",
      "X Shape (2764, 11, 10, 10)\n",
      "max yardIndex:  203.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  85.0\n",
      "min yardIndexClipped:  85.0\n",
      "y Shape (2764, 80)\n",
      "Train X (2487, 11, 10, 10)\n",
      "Test X (277, 11, 10, 10)\n",
      "Train y (2487, 80)\n",
      "Test y (277, 80)\n",
      "2259\n",
      "X Shape (2259, 11, 10, 10)\n",
      "max yardIndex:  198.0\n",
      "max yardIndexClipped:  150.0\n",
      "min yardIndex:  86.0\n",
      "min yardIndexClipped:  86.0\n",
      "y Shape (2259, 80)\n",
      "Train X (2033, 11, 10, 10)\n",
      "Test X (226, 11, 10, 10)\n",
      "Train y (2033, 80)\n",
      "Test y (226, 80)\n",
      "X_train_combo (4520, 11, 10, 10)\n",
      "X_test_combo (503, 11, 10, 10)\n",
      "y_train_combo (4520, 80)\n",
      "y_test_combo (503, 80)\n",
      "X_train_combo Shuffled (4520, 11, 10, 10)\n",
      "y_train_combo Shuffled (4520, 80)\n"
     ]
    }
   ],
   "source": [
    "X_train_comb_tensor, X_test_comb_tensor, y_train_comb_tensor, y_test_comb_tensor = get_input_data_combo(play_track_df, punt_play_track_df, \"\", test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
